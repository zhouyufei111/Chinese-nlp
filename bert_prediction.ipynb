{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d037d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "from torch.nn import functional as F\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch.optim import lr_scheduler\n",
    "from datetime import datetime,timedelta,timezone\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "235cf49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'bert_chinese/'\n",
    "directory_path = 'HSMS/TrainingSet/test_drive/'\n",
    "file_path = directory_path + 'test.csv'\n",
    "\n",
    "weight_path = \"Loss-v5.bin\"\n",
    "\n",
    "config = {\n",
    "          \"epochs\": 10,\n",
    "          \"batch_size\": 16,\n",
    "          \"max_length\": 64,\n",
    "          \"lr\": 1e-5,\n",
    "          \"weight_decay\": 1e-6,           \n",
    "          \"num_classes\": 8,\n",
    "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "          \"tokenizer\" : BertTokenizer.from_pretrained(model_path)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335e30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "encoder = pickle. load(open('encoder_for_test_drive', \"rb\"))\n",
    "df['label'] = encoder.fit_transform(df['Aspect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9981716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestdriveDataset(Dataset):\n",
    "    def __init__(self, df, max_length):\n",
    "        self.text = df['text'].values\n",
    "        self.target = df['label'].values\n",
    "        self.max_length = max_length\n",
    "      \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self,ids):\n",
    "        tokenizer = config['tokenizer']\n",
    "        text = self.text[ids]\n",
    "        target = self.target[ids]\n",
    "        inputs = tokenizer.encode_plus(text,\n",
    "                      truncation=True,\n",
    "                      add_special_tokens=True,\n",
    "                      max_length = self.max_length\n",
    "                      )\n",
    "        \n",
    "        data_dict = {'input_ids' : inputs['input_ids'],\n",
    "                    'attention_mask': inputs['attention_mask'],\n",
    "                    'target': target}\n",
    "        \n",
    "        \n",
    "        return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ced53f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=config['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3a70179",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestdriveModel(nn.Module):\n",
    "    def __init__(self,drop_rate):\n",
    "        super(TestdriveModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_path)\n",
    "        self.drop = nn.Dropout(drop_rate)\n",
    "        self.fc = nn.Linear(768, config['num_classes'])\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids=input_ids,\n",
    "                       attention_mask=attention_mask)\n",
    "        \n",
    "        output = self.drop(output.last_hidden_state[:,0])\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ddb4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid(model, dataloader,device):\n",
    "    model.eval()\n",
    "    \n",
    "    prediction_list = []\n",
    "    pbar = tqdm(enumerate(dataloader))\n",
    "    for step, data in pbar:\n",
    "        input_ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        attention_mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        target = torch.LongTensor(data['target'])\n",
    "        \n",
    "        output = model(input_ids, attention_mask)\n",
    "        \n",
    "        output = F.softmax(output,dim=1)\n",
    "        prediction = output.argmax(1)\n",
    "        prediction_list.extend(prediction.cpu().detach().numpy())\n",
    "\n",
    "      \n",
    "        \n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1df1bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestdriveDataset(df,max_length = config['max_length'])\n",
    "test_loader = DataLoader(test_dataset, shuffle = False, batch_size = config['batch_size'], drop_last = False,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8b6002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model_paths, dataloader, device):\n",
    "    \n",
    "\n",
    "    print('start')\n",
    "    model = TestdriveModel(0.2)\n",
    "    model.to(config['device'])\n",
    "    model.load_state_dict(torch.load(model_paths))\n",
    "\n",
    "    \n",
    "    preds = valid(model, dataloader, device)\n",
    "\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf7c47c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert_chinese/ were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "78it [00:10,  7.36it/s]\n"
     ]
    }
   ],
   "source": [
    "model_preds = inference(weight_path, test_loader, config['device'])\n",
    "df['prediction'] = encoder.inverse_transform(model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b17ae436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(df,directory_path):\n",
    "    timezone_offset = +8.0 \n",
    "    tzinfo = timezone(timedelta(hours=timezone_offset))\n",
    "    current_date =  datetime.now(tzinfo)\n",
    "    Date_of_today = ('0' + str(current_date.month) if len(str(current_date.month))<2 else str(current_date.month)) + ('0' + str(current_date.day) if len(str(current_date.day))<2 else str(current_date.day))\n",
    "    file_name =  f'prediction {Data_of_today}'\n",
    "    df.to_excel(directory_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "913cf502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9686998394863563"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Aspect'] == df['prediction']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "883fe774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "520389cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74536d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1018'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2945d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
